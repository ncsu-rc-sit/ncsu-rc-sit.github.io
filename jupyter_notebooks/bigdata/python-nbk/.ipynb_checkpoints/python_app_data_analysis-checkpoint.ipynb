{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Tabular Data into DataFrames\n",
    "\n",
    "Pandas is a widely-used Python library for statistics, particularly on tabular data.\n",
    "\n",
    "First time use (Installing via cmd):\n",
    "\n",
    "`pip install pandas`\n",
    "\n",
    "Loading:\n",
    "\n",
    "`import pandas as pd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/gapminder_gdp_oceania.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The columns in a dataframe are the observed variables, and the rows are the observations.\n",
    "+ Pandas uses backslash `\\` to show wrapped lines when output is too wide to fit the screen.\n",
    "\n",
    "### Using `index_col` to specify a column's name as row headings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/gapminder_gdp_oceania.csv', index_col='country')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataFrame.info` - Getting more information about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ This is a DataFrame\n",
    "+ Two rows named 'Australia' and 'New Zealand'\n",
    "+ Twelve columns, each of which has two actual 64-bit floating point values.\n",
    "+ Uses 208 bytes of memory.\n",
    "\n",
    "### `DataFrame.columns` - variable that stores information about the dataframe’s columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataFrame.T` - Is used to Transpose  a dataframe\n",
    "\n",
    "+ Sometimes want to treat columns as rows and vice versa.\n",
    "+ Transpose (written `.T`) doesn’t copy the data, just changes the program’s view of it.\n",
    "+ Like `columns`, it is a member variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataFrame.describe` - Is used to get the summary of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas DataFrames/Series\n",
    "\n",
    "A DataFrame is a collection of Series; The DataFrame is the way Pandas represents a table, and Series is the data-structure Pandas use to represent a column.\n",
    "\n",
    "Pandas is built on top of the Numpy library, which in practice means that most of the methods defined for Numpy Arrays apply to Pandas Series/DataFrames.\n",
    "\n",
    "What makes Pandas so attractive is the powerful interface to access individual records of the table, proper handling of missing values, and relational-databases operations between DataFrames.\n",
    "\n",
    "### Selecting values\n",
    "\n",
    "To access a value at the position `[i,j]` of a DataFrame, we have two options, depending on what is the meaning of `i` in use. Remember that a DataFrame provides an index as a way to identify the rows of the table; a row, then, has a position inside the table as well as a label, which uniquely identifies its entry in the DataFrame.\n",
    "\n",
    "### `DataFrame.iloc[..., ...]` - Is used to select the values  by their (entry) position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/gapminder_gdp_europe.csv', index_col='country')\n",
    "print(data.iloc[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataFrame.loc[..., ...]`  - Is used to select the values by their (entry) label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/gapminder_gdp_europe.csv', index_col='country')\n",
    "print(data.loc[\"Albania\", \"gdpPercap_1952\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `:` - Use this on its own to mean all columns or all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.loc[\"Albania\", :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.loc[:, \"gdpPercap_1952\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select multiple columns or rows using `DataFrame.loc` and a named slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.loc['Italy':'Poland', 'gdpPercap_1962':'gdpPercap_1972'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of slicing can be used in further operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.loc['Italy':'Poland', 'gdpPercap_1962':'gdpPercap_1972'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.loc['Italy':'Poland', 'gdpPercap_1962':'gdpPercap_1972'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use comparisons to select data based on value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a subset of data to keep output readable.\n",
    "subset = data.loc['Italy':'Poland', 'gdpPercap_1962':'gdpPercap_1972']\n",
    "print('Subset of data:\\n', subset)\n",
    "\n",
    "# Which values were greater than 10000 ?\n",
    "print('\\nWhere are values large?\\n', subset > 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select values or NaN using a Boolean mask.\n",
    "\n",
    "A frame full of Booleans is sometimes called a mask because of how it can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = subset > 10000\n",
    "print(subset[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subset[subset > 10000].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group By: split-apply-combine\n",
    "\n",
    "Pandas vectorizing methods and grouping operations are features that provide users much flexibility to analyse their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_higher = data > data.mean()\n",
    "wealth_score = mask_higher.aggregate('sum', axis=1) / len(data.columns)\n",
    "wealth_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code snippet\n",
    "We wanted to have clearer view of  on how the European countries split themselves according to their GDP.\n",
    "\n",
    "1. We may have a glance by splitting the countries in two groups during the years surveyed, those who presented a GDP higher than the European average and those with a lower GDP.\n",
    "2. We then estimate a wealthy score based on the historical (from 1962 to 2007) values, where we account how many times a country has participated in the groups of lower or higher GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(wealth_score).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code snippet for each group in the wealth_score table, we sum their (financial) contribution across the years surveyed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "### `matplotlib` is the most widely used scientific plotting library in Python.\n",
    "\n",
    "+ Commonly use a sub-library called matplotlib.pyplot.\n",
    "+ The Jupyter Notebook will render plots inline if we ask it to using a “magic” command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = [0, 1, 2, 3]\n",
    "position = [0, 100, 200, 300]\n",
    "\n",
    "plt.plot(time, position)\n",
    "plt.xlabel('Time (hr)')\n",
    "plt.ylabel('Position (km)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data directly from a `Pandas dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/gapminder_gdp_oceania.csv', index_col='country')\n",
    "\n",
    "# Extract year from last 4 characters of each column name\n",
    "# The current column names are structured as 'gdpPercap_(year)', \n",
    "# so we want to keep the (year) part only for clarity when plotting GDP vs. years\n",
    "# To do this we use strip(), which removes from the string the characters stated in the argument\n",
    "# This method works on strings, so we call str before strip()\n",
    "\n",
    "years = data.columns.str.strip('gdpPercap_')\n",
    "\n",
    "# Convert year values to integers, saving results back to dataframe\n",
    "\n",
    "data.columns = years.astype(int)\n",
    "\n",
    "data.loc['Australia'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot data directly from a `Pandas dataframe`.\n",
    "\n",
    "+ We can also plot Pandas dataframes.\n",
    "+ This implicitly uses `matplotlib.pyplot`.\n",
    "+ Before plotting, we convert the column headings from a string to integer data type, since they represent numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/gapminder_gdp_oceania.csv', index_col='country')\n",
    "\n",
    "# Extract year from last 4 characters of each column name\n",
    "# The current column names are structured as 'gdpPercap_(year)', \n",
    "# so we want to keep the (year) part only for clarity when plotting GDP vs. years\n",
    "# To do this we use strip(), which removes from the string the characters stated in the argument\n",
    "# This method works on strings, so we call str before strip()\n",
    "\n",
    "years = data.columns.str.strip('gdpPercap_')\n",
    "\n",
    "# Convert year values to integers, saving results back to dataframe\n",
    "\n",
    "data.columns = years.astype(int)\n",
    "\n",
    "data.loc['Australia'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and transform data, then plot it.\n",
    "+ By default, DataFrame.plot plots with the rows as the X axis.\n",
    "+ We can transpose the data in order to plot multiple series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.T.plot()\n",
    "plt.ylabel('GDP per capita')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different styles of plots (Bar Graph)\n",
    "plt.style.use('ggplot')\n",
    "data.T.plot(kind='bar')\n",
    "plt.ylabel('GDP per capita')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot multiple datasets together\n",
    "\n",
    "# Select two countries' worth of data.\n",
    "gdp_australia = data.loc['Australia']\n",
    "gdp_nz = data.loc['New Zealand']\n",
    "\n",
    "# Plot with differently-colored markers.\n",
    "plt.plot(years, gdp_australia, 'b-', label='Australia') # This is making labels\n",
    "plt.plot(years, gdp_nz, 'g-', label='New Zealand')\n",
    "\n",
    "# Create legend.\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('GDP per capita ($)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(gdp_australia, gdp_nz) # This gives the correlation between the GDP's of the two countries Australia and New Zealand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving your plot to a file\n",
    "\n",
    "If you are satisfied with the plot you see you may want to save it to a file, perhaps to include it in a publication. There is a function in the matplotlib.pyplot module that accomplishes this: savefig. Calling this function, e.g. with\n",
    "\n",
    "```python\n",
    "plt.savefig('my_figure.png')\n",
    "```\n",
    "\n",
    "will save the current figure to the file my_figure.png. The file format will automatically be deduced from the file name extension (other formats are pdf, ps, eps and svg).\n",
    "\n",
    "# Analyzing Patient Data\n",
    "\n",
    "### Loading data into Python\n",
    "\n",
    "<u> Using Inflamation data for this </u>\n",
    "    \n",
    "+ We can do that using a library called NumPy, which stands for Numerical Python.\n",
    "+ To tell Python that we’d like to start using NumPy, we need to import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "numpy.loadtxt(fname='data\\inflammation-01.csv', delimiter=',') # `loadtxt` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our call to numpy.loadtxt read our file but didn’t save the data in memory.\n",
    "#To do that, we need to assign the array to a variable. \n",
    "#In a similar manner to how we assign a single value to a variable,\n",
    "## we can also assign an array of values to a variable using the same syntax. \n",
    "# Let’s re-run numpy.loadtxt and save the returned data:\n",
    "\n",
    "data = numpy.loadtxt(fname='data\\inflammation-01.csv', delimiter=',')\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the data has 60 rows and 40 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('first value in data:', data[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('first value in data:', data[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('middle value in data:', data[30, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image1](data\\image1.png \"Data\")\n",
    "\n",
    "We can visualize the data like this\n",
    "\n",
    "### Slicing data\n",
    "\n",
    "An index like `[30, 20]` selects a single element of an array, but we can select whole sections as well. For example, we can select the first ten days (columns) of values for the first four patients (rows) like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0:4, 0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slice `0:4` means, “Start at index 0 and go up to, but not including, index 4”. Again, the up-to-but-not-including takes a bit of getting used to, but the rule is that the difference between the upper and lower bounds is the number of values in the slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[5:10, 0:10]) # We dont need to start at '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can ignore the upper/lower bounds python will take care of it \n",
    "small = data[:3, 36:]\n",
    "print('small is:')\n",
    "print(small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing data\n",
    "we can ask NumPy to compute data’s mean value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numpy.mean(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple value assignment\n",
    "maxval, minval, stdval = numpy.max(data), numpy.min(data), numpy.std(data)\n",
    "\n",
    "print('maximum inflammation:', maxval)\n",
    "print('minimum inflammation:', minval)\n",
    "print('standard deviation:', stdval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When analyzing data, though, we often want to look at variations in statistical values, such as the maximum inflammation per patient or the average inflammation per day. One way to do this is to create a new temporary array of the data we want, then ask it to do the calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_0 = data[0, :] # 0 on the first axis (rows), everything on the second (columns)\n",
    "print('maximum inflammation for patient 0:', numpy.max(patient_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don’t actually need to store the row in a variable of its own. Instead, we can combine the selection and the function call:\n",
    "print('maximum inflammation for patient 2:', numpy.max(data[2, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize like this\n",
    "What if we need the maximum inflammation for each patient over all days (as in the next diagram on the left) or the average for each day (as in the diagram on the right)? As the diagram below shows, we want to perform the operation across an axis:\n",
    "\n",
    "![image2](data\\image2.png \"Data\")\n",
    "\n",
    "To support this functionality, most array functions allow us to specify the axis we want to work on. If we ask for the average across axis 0 (rows in our 2D example), we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numpy.mean(data, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a quick check, we can ask this array what its shape is:\n",
    "print(numpy.mean(data, axis=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numpy.mean(data, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will import the pyplot module from matplotlib and use two of its functions to create and display a heat map of our data:\n",
    "import matplotlib.pyplot\n",
    "image = matplotlib.pyplot.imshow(data)\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blue pixels in this heat map represent low values, while yellow pixels represent high values. As we can see, inflammation rises and falls over a 40-day period. Let’s take a look at the average inflammation over time:\n",
    "\n",
    "```python\n",
    "ave_inflammation = numpy.mean(data, axis=0)\n",
    "ave_plot = matplotlib.pyplot.plot(ave_inflammation)\n",
    "matplotlib.pyplot.show()\n",
    "```\n",
    "<mark> Run the code snippets to see the result</mark> \n",
    "\n",
    "Here, we have put the average inflammation per day across all patients in the variable ave_inflammation, then asked matplotlib.pyplot to create and display a line graph of those values. The result is a roughly linear rise and fall, which is suspicious: we might instead expect a sharper rise and slower fall. Let’s have a look at two other statistics:\n",
    "\n",
    "<b> These are used to get max and min plots </b>\n",
    "```python\n",
    "max_plot = matplotlib.pyplot.plot(numpy.max(data, axis=0))\n",
    "matplotlib.pyplot.show()\n",
    "```\n",
    "```python\n",
    "min_plot = matplotlib.pyplot.plot(numpy.min(data, axis=0))\n",
    "matplotlib.pyplot.show()\n",
    "```\n",
    "\n",
    "#### Grouping plots\n",
    "\n",
    "The function `matplotlib.pyplot.figure()` creates a space into which we will place all of our plots. The parameter figsize tells Python how big to make this space. Each subplot is placed into the figure using its `add_subplot` method. The `add_subplot` method takes 3 parameters. The first denotes how many total rows of subplots there are, the second parameter refers to the total number of subplot columns, and the final parameter denotes which subplot your variable is referencing (left-to-right, top-to-bottom). Each subplot is stored in a different variable (`axes1`, `axes2`, `axes3`). Once a subplot is created, the axes can be titled using the `set_xlabel()` command (or `set_ylabel()`). Here are our three plots side by side:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "\n",
    "data = numpy.loadtxt(fname='data\\inflammation-01.csv', delimiter=',')\n",
    "\n",
    "fig = matplotlib.pyplot.figure(figsize=(10.0, 3.0))\n",
    "\n",
    "axes1 = fig.add_subplot(1, 3, 1)\n",
    "axes2 = fig.add_subplot(1, 3, 2)\n",
    "axes3 = fig.add_subplot(1, 3, 3)\n",
    "\n",
    "axes1.set_ylabel('average')\n",
    "axes1.plot(numpy.mean(data, axis=0))\n",
    "\n",
    "axes2.set_ylabel('max')\n",
    "axes2.plot(numpy.max(data, axis=0))\n",
    "\n",
    "axes3.set_ylabel('min')\n",
    "axes3.plot(numpy.min(data, axis=0))\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "matplotlib.pyplot.savefig('inflammation.png')\n",
    "matplotlib.pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Data from Multiple Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `glob` library contains a function, also called `glob`, that finds files and directories whose names match a pattern. We provide those patterns as strings: the character `*` matches zero or more characters, while `?` matches any one character. We can use this to get the names of all the CSV files in the current directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glob.glob('data\\inflammation*.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ As these examples show, glob.glob’s result is a list of file and directory paths in arbitrary order.\n",
    "+ This means we can loop over it to do something with each filename in turn.\n",
    "+ In our case, the “something” we want to do is generate a set of plots for each file in our inflammation dataset.\n",
    "+ If we want to start by analyzing just the first three files in alphabetical order, we can use the sorted built-in function to generate a new sorted list from the glob.glob output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "\n",
    "filenames = sorted(glob.glob('data\\inflammation*.csv'))\n",
    "filenames = filenames[0:3]\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "\n",
    "    data = numpy.loadtxt(fname=filename, delimiter=',')\n",
    "\n",
    "    fig = matplotlib.pyplot.figure(figsize=(10.0, 3.0))\n",
    "\n",
    "    axes1 = fig.add_subplot(1, 3, 1)\n",
    "    axes2 = fig.add_subplot(1, 3, 2)\n",
    "    axes3 = fig.add_subplot(1, 3, 3)\n",
    "\n",
    "    axes1.set_ylabel('average')\n",
    "    axes1.plot(numpy.mean(data, axis=0))\n",
    "\n",
    "    axes2.set_ylabel('max')\n",
    "    axes2.plot(numpy.max(data, axis=0))\n",
    "\n",
    "    axes3.set_ylabel('min')\n",
    "    axes3.plot(numpy.min(data, axis=0))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    matplotlib.pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping Over Data Sets\n",
    "\n",
    "#### Use a `for` loop to process files given a list of their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for filename in ['data/gapminder_gdp_africa.csv', 'data/gapminder_gdp_asia.csv']:\n",
    "    data = pd.read_csv(filename, index_col='country')\n",
    "    print(filename, data.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `glob.glob` to find sets of files whose names match a pattern.\n",
    "\n",
    "+ In Unix, the term “globbing” means “matching a set of files with a pattern”.\n",
    "+ The most common patterns are:\n",
    "  + `*` meaning “match zero or more characters”\n",
    "  + `?` meaning “match exactly one character”\n",
    "+ Python’s standard library contains the `glob` module to provide pattern matching functionality\n",
    "+ The `glob` module contains a function also called glob to match file patterns\n",
    "+ E.g., `glob.glob('*.txt')` matches all files in the current directory whose names end with .txt.\n",
    "+ Result is a (possibly empty) list of character strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "print('all csv files in data directory:', glob.glob('data/*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('all PDB files:', glob.glob('*.pdb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `glob` and `for` to process batches of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helps a lot if the files are named and stored systematically and consistently so that simple patterns will find the right data.\n",
    "for filename in glob.glob('data/gapminder_*.csv'):\n",
    "    data = pd.read_csv(filename)\n",
    "    print(filename, data['gdpPercap_1952'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This includes all data, as well as per-region data.\n",
    "Use a more specific pattern in the exercises to exclude the whole data set.\n",
    "But note that the minimum of the entire data set is also the minimum of one of the data sets, which is a nice check on correctness.\n",
    "\n",
    "# Creating Functions\n",
    "\n",
    "Let’s start by defining a function `fahr_to_celsius` that converts temperatures from Fahrenheit to Celsius:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fahr_to_celsius(temp):\n",
    "    return ((temp - 32) * (5/9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image3](data\\image3.png \"Data\")\n",
    "\n",
    "```python\n",
    "fahr_to_celsius(32)\n",
    "```\n",
    "This command should call our function, using “32” as the input and return the function value.\n",
    "\n",
    "In fact, calling our own function is no different from calling any other function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('freezing point of water:', fahr_to_celsius(32), 'C')\n",
    "print('boiling point of water:', fahr_to_celsius(212), 'C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Composing Functions\n",
    "\n",
    "Now that we’ve seen how to turn Fahrenheit into Celsius, we can also write the function to turn Celsius into Kelvin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def celsius_to_kelvin(temp_c):\n",
    "    return temp_c + 273.15\n",
    "\n",
    "print('freezing point of water in Kelvin:', celsius_to_kelvin(0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidying up\n",
    "\n",
    "Now that we know how to wrap bits of code up in functions, we can make our inflammation analysis easier to read and easier to reuse. First, let’s make a visualize function that generates our plots:\n",
    "\n",
    "```python\n",
    "def visualize(filename):\n",
    "\n",
    "    data = numpy.loadtxt(fname=filename, delimiter=',')\n",
    "\n",
    "    fig = matplotlib.pyplot.figure(figsize=(10.0, 3.0))\n",
    "\n",
    "    axes1 = fig.add_subplot(1, 3, 1)\n",
    "    axes2 = fig.add_subplot(1, 3, 2)\n",
    "    axes3 = fig.add_subplot(1, 3, 3)\n",
    "\n",
    "    axes1.set_ylabel('average')\n",
    "    axes1.plot(numpy.mean(data, axis=0))\n",
    "\n",
    "    axes2.set_ylabel('max')\n",
    "    axes2.plot(numpy.max(data, axis=0))\n",
    "\n",
    "    axes3.set_ylabel('min')\n",
    "    axes3.plot(numpy.min(data, axis=0))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    matplotlib.pyplot.show()\n",
    "```\n",
    "\n",
    "and another function called `detect_problems` that checks for those systematics we noticed:\n",
    "\n",
    "```python\n",
    "def detect_problems(filename):\n",
    "\n",
    "    data = numpy.loadtxt(fname=filename, delimiter=',')\n",
    "\n",
    "    if numpy.max(data, axis=0)[0] == 0 and numpy.max(data, axis=0)[20] == 20:\n",
    "        print('Suspicious looking maxima!')\n",
    "    elif numpy.sum(numpy.min(data, axis=0)) == 0:\n",
    "        print('Minima add up to zero!')\n",
    "    else:\n",
    "        print('Seems OK!')\n",
    "```\n",
    "\n",
    "We can reproduce the previous analysis with a much simpler for loop:\n",
    "\n",
    "```python\n",
    "filenames = sorted(glob.glob('data/inflammation*.csv'))\n",
    "\n",
    "for filename in filenames[:3]:\n",
    "    print(filename)\n",
    "    visualize(filename)\n",
    "    detect_problems(filename)\n",
    "```\n",
    "\n",
    "Here is the implemeantation....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(filename):\n",
    "\n",
    "    data = numpy.loadtxt(fname=filename, delimiter=',')\n",
    "\n",
    "    fig = matplotlib.pyplot.figure(figsize=(10.0, 3.0))\n",
    "\n",
    "    axes1 = fig.add_subplot(1, 3, 1)\n",
    "    axes2 = fig.add_subplot(1, 3, 2)\n",
    "    axes3 = fig.add_subplot(1, 3, 3)\n",
    "\n",
    "    axes1.set_ylabel('average')\n",
    "    axes1.plot(numpy.mean(data, axis=0))\n",
    "\n",
    "    axes2.set_ylabel('max')\n",
    "    axes2.plot(numpy.max(data, axis=0))\n",
    "\n",
    "    axes3.set_ylabel('min')\n",
    "    axes3.plot(numpy.min(data, axis=0))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_problems(filename):\n",
    "\n",
    "    data = numpy.loadtxt(fname=filename, delimiter=',')\n",
    "\n",
    "    if numpy.max(data, axis=0)[0] == 0 and numpy.max(data, axis=0)[20] == 20:\n",
    "        print('Suspicious looking maxima!')\n",
    "    elif numpy.sum(numpy.min(data, axis=0)) == 0:\n",
    "        print('Minima add up to zero!')\n",
    "    else:\n",
    "        print('Seems OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = sorted(glob.glob('data\\inflammation*.csv'))\n",
    "\n",
    "for filename in filenames[:3]:\n",
    "    print(filename)\n",
    "    visualize(filename)\n",
    "    detect_problems(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Documenting\n",
    "\n",
    "Once we start putting things in functions so that we can re-use them, we need to start testing that those functions are working correctly. To see how to do this, let’s write a function to offset a dataset so that it’s mean value shifts to a user-defined value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offset_mean(data, target_mean_value):\n",
    "    return (data - numpy.mean(data)) + target_mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = numpy.zeros((2,2))\n",
    "print(offset_mean(z, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That looks right, so let’s try offset_mean on our real data:\n",
    "data = numpy.loadtxt(fname='data\\inflammation-01.csv', delimiter=',')\n",
    "print(offset_mean(data, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s hard to tell from the default output whether the result is correct, but there are a few tests that we can run to reassure us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('original min, mean, and max are:', numpy.min(data), numpy.mean(data), numpy.max(data))\n",
    "offset_data = offset_mean(data, 0)\n",
    "print('min, mean, and max of offset data are:',\n",
    "      numpy.min(offset_data),\n",
    "      numpy.mean(offset_data),\n",
    "      numpy.max(offset_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems almost right: the original mean was about 6.1, so the lower bound from zero is now about -6.1. The mean of the offset data isn’t quite zero — we’ll explore why not in the challenges — but it’s pretty close. We can even go further and check that the standard deviation hasn’t changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('std dev before and after:', numpy.std(data), numpy.std(offset_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those values look the same, but we probably wouldn’t notice if they were different in the sixth decimal place. Let’s do this instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('difference in standard deviations before and after:',\n",
    "      numpy.std(data) - numpy.std(offset_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the difference is very small. It’s still possible that our function is wrong, but it seems unlikely enough that we should probably get back to doing our analysis. We have one more task first, though: we should write some documentation for our function to remind ourselves later what it’s for and how to use it.\n",
    "\n",
    "The usual way to put documentation in software is to add comments like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offset_mean(data, target_mean_value):\n",
    "# return a new array containing the original data with its mean offset to match the desired value.\n",
    "def offset_mean(data, target_mean_value):\n",
    "    return (data - numpy.mean(data)) + target_mean_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There’s a better way, though. If the first thing in a function is a string that isn’t assigned to a variable, that string is attached to the function as its documentation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offset_mean(data, target_mean_value):\n",
    "    \"\"\"Return a new array containing the original data\n",
    "       with its mean offset to match the desired value.\"\"\"\n",
    "    return (data - numpy.mean(data)) + target_mean_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better because we can now ask Python’s built-in help system to show us the documentation for the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(offset_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A string like this is called a docstring. We don’t need to use triple quotes when we write one, but if we do, we can break the string across multiple lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offset_mean(data, target_mean_value):\n",
    "    \"\"\"Return a new array containing the original data\n",
    "       with its mean offset to match the desired value.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> offset_mean([1, 2, 3], 0)\n",
    "    array([-1.,  0.,  1.])\n",
    "    \"\"\"\n",
    "    return (data - numpy.mean(data)) + target_mean_value\n",
    "\n",
    "help(offset_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors and Exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code has an intentional error. You can type it directly or\n",
    "# use it for reference to understand the error message below.\n",
    "def favorite_ice_cream():\n",
    "    ice_creams = [\n",
    "        'chocolate',\n",
    "        'vanilla',\n",
    "        'strawberry'\n",
    "    ]\n",
    "    print(ice_creams[3])\n",
    "\n",
    "favorite_ice_cream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular traceback has two levels. You can determine the number of levels by looking for the number of arrows on the left hand side. In this case:\n",
    "\n",
    "1. The first shows code from the cell above, with an arrow pointing to Line 11 (which is `favorite_ice_cream()`).\n",
    "\n",
    "2. The second shows some code in the function `favorite_ice_cream`, with an arrow pointing to Line 9 (which is `print(ice_creams[3])`).\n",
    "\n",
    "The last level is the actual place where the error occurred. The other level(s) show what function the program executed to get to the next level down. So, in this case, the program first performed a function call to the function `favorite_ice_cream`. Inside this function, the program encountered an error on Line 6, when it tried to run the code `print(ice_creams[3]`).\n",
    "\n",
    "So what error did the program actually encounter? In the last line of the traceback, Python helpfully tells us the category or type of error (in this case, it is an IndexError) and a more detailed error message (in this case, it says “list index out of range”).\n",
    "\n",
    "If you encounter an error and don’t know what it means, it is still important to read the traceback closely. That way, if you fix the error, but encounter a new one, you can tell that the error changed. Additionally, sometimes knowing where the error occurred is enough to fix it, even if you don’t entirely understand the message.\n",
    "\n",
    "If you do encounter an error you don’t recognize, try looking at the official documentation on errors. However, note that you may not always be able to find the error there, as it is possible to create custom errors. In that case, hopefully the custom error message is informative enough to help you figure out what went wrong.\n",
    "\n",
    "### Syntax Errors\n",
    "When you forget a colon at the end of a line, accidentally add one space too many when indenting under an `if` statement, or forget a parenthesis, you will encounter a syntax error. This means that Python couldn’t figure out how to read your program. This is similar to forgetting punctuation in English: for example, this text is difficult to read there is no punctuation there is also no capitalization why is this hard because you have to figure out where each sentence ends you also have to figure out where each sentence begins to some extent it might be ambiguous if there should be a sentence break or not\n",
    "\n",
    "People can typically figure out what is meant by text with no punctuation, but people are much smarter than computers. If Python doesn’t know how to read the program, it will give up and inform you with an error. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_function()\n",
    "    msg = 'hello, world!'\n",
    "    print(msg)\n",
    "     return msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, Python tells us that there is a `SyntaxError` on line 1, and even puts a little arrow in the place where there is an issue. In this case the problem is that the function definition is missing a colon at the end.\n",
    "\n",
    "Actually, the function above has two issues with syntax. If we fix the problem with the colon, we see that there is also an `IndentationError`, which means that the lines in the function definition do not all have the same indentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_function():\n",
    "    msg = 'hello, world!'\n",
    "    print(msg)\n",
    "     return msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both `SyntaxError` and `IndentationError` indicate a problem with the syntax of your program, but an `IndentationError` is more specific: it always means that there is a problem with how your code is indented.\n",
    "\n",
    "Some indentation errors are harder to spot than others. In particular, mixing spaces and tabs can be difficult to spot because they are both whitespace. In the example below, the first two lines in the body of the function `some_function` are indented with tabs, while the third line — with spaces. If you’re working in a Jupyter notebook, be sure to copy and paste this example rather than trying to type it in manually because Jupyter automatically replaces tabs with spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_function():\n",
    "\tmsg = 'hello, world!'\n",
    "\tprint(msg)\n",
    "        return msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Name Errors\n",
    "\n",
    "Another very common type of error is called a NameError, and occurs when you try to use a variable that does not exist. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Errors\n",
    "Next up are errors having to do with containers (like lists and strings) and the items within them. If you try to access an item in a list or a string that does not exist, then you will get an error. This makes sense: if you asked someone what day they would like to get coffee, and they answered “caturday”, you might be a bit annoyed. Python gets similarly annoyed if you try to ask it for an item that doesn’t exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['a', 'b', 'c']\n",
    "print('Letter #1 is', letters[0])\n",
    "print('Letter #2 is', letters[1])\n",
    "print('Letter #3 is', letters[2])\n",
    "print('Letter #4 is', letters[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, Python is telling us that there is an IndexError in our code, meaning we tried to access a list index that did not exist.\n",
    "\n",
    "### File Errors\n",
    "\n",
    "The last type of error we’ll cover today are those associated with reading and writing files: `FileNotFoundError`. If you try to read a file that does not exist, you will receive a `FileNotFoundError` telling you so. If you attempt to write to a file that was opened read-only, Python 3 returns an `UnsupportedOperationError`. More generally, problems with input and output manifest as `IOErrors` or `OSErrors`, depending on the version of Python you use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_handle = open('myfile.txt', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One reason for receiving this error is that you specified an incorrect path to the file. For example, if I am currently in a folder called `myproject`, and I have a file in `myproject/writing/myfile.txt`, but I try to open `myfile.txt`, this will fail. The correct path would be `writing/myfile.txt`. It is also possible that the file name or its path contains a typo.\n",
    "\n",
    "A related issue can occur if you use the “read” flag instead of the “write” flag. Python will not give you an error if you try to open a file for writing when the file does not exist. However, if you meant to open a file for reading, but accidentally opened it for writing, and then try to read from it, you will get an `UnsupportedOperation` error telling you that the file was not opened for reading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_handle = open('myfile.txt', 'w')\n",
    "file_handle.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the most common errors with files, though many others exist. If you get an error that you’ve never seen before, searching the Internet for that error type often reveals common reasons why you might get that error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
